{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMvA5LQsavIVDSiltzKZ7CO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"eExoNcV2g4I9"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import random\n","\n","# Set random seed for reproducibility\n","random.seed(42)\n","np.random.seed(42)\n","\n","# Sample data for mental health classification\n","depression_texts = [\n","    \"I feel so empty inside, nothing seems to matter anymore\",\n","    \"I can't get out of bed, everything feels pointless\",\n","    \"I'm tired all the time and have no energy for anything\",\n","    \"I feel like I'm drowning in sadness and can't escape\",\n","    \"Nothing brings me joy anymore, I feel numb\",\n","    \"I hate myself and feel worthless every day\",\n","    \"I can't stop crying and feel hopeless about the future\",\n","    \"Sleep is my only escape from this overwhelming sadness\",\n","    \"I feel like a burden to everyone around me\",\n","    \"Life feels meaningless and I don't see the point\",\n","    \"I've lost interest in everything I used to enjoy\",\n","    \"I feel trapped in this dark place with no way out\",\n","    \"Every day is a struggle just to exist\",\n","    \"I feel so alone even when surrounded by people\",\n","    \"I can't remember the last time I felt genuinely happy\",\n","    \"Everything feels like too much effort lately\",\n","    \"I feel disconnected from myself and others\",\n","    \"The world seems gray and colorless to me\",\n","    \"I constantly feel guilty about everything\",\n","    \"I have no motivation to do anything anymore\"\n","]\n","\n","anxiety_texts = [\n","    \"My heart is racing and I can't calm down\",\n","    \"I'm constantly worried about everything that could go wrong\",\n","    \"I feel like I'm having a panic attack right now\",\n","    \"What if something terrible happens to my family?\",\n","    \"I can't stop overthinking every little detail\",\n","    \"My mind is racing with worst-case scenarios\",\n","    \"I feel like everyone is judging me constantly\",\n","    \"I'm terrified of making mistakes or failing\",\n","    \"I can't breathe properly, my chest feels tight\",\n","    \"What if I embarrass myself in front of everyone?\",\n","    \"I'm shaking and sweating for no reason\",\n","    \"I feel like something bad is about to happen\",\n","    \"I can't concentrate because of all these worries\",\n","    \"My stomach is in knots from anxiety\",\n","    \"I avoid social situations because they make me panic\",\n","    \"I keep checking things over and over again\",\n","    \"What if I'm not good enough for this job?\",\n","    \"I feel like I'm losing control of everything\",\n","    \"I'm scared of being alone with my thoughts\",\n","    \"Every phone call makes me anxious about bad news\"\n","]\n","\n","neutral_texts = [\n","    \"I had a pretty good day at work today\",\n","    \"Just finished watching a great movie with friends\",\n","    \"Planning to go for a walk in the park this weekend\",\n","    \"Learning to cook a new recipe, it's challenging but fun\",\n","    \"Had an interesting conversation with my neighbor\",\n","    \"Reading a fascinating book about science\",\n","    \"The weather is nice today, perfect for outdoor activities\",\n","    \"Just completed my morning workout routine\",\n","    \"Enjoying my coffee while listening to music\",\n","    \"Had a productive meeting with my team\",\n","    \"Trying out a new restaurant this evening\",\n","    \"My garden is looking beautiful this season\",\n","    \"Just caught up with an old friend over video call\",\n","    \"Working on organizing my home office space\",\n","    \"Planning a weekend trip to visit family\",\n","    \"Attended an interesting online workshop today\",\n","    \"My cat did something amusing this morning\",\n","    \"Finished reading the news and having breakfast\",\n","    \"Looking forward to the upcoming holiday season\",\n","    \"Had a normal day, nothing special happened\"\n","]\n","\n","# Create dataset\n","data = []\n","\n","# Add depression samples\n","for text in depression_texts:\n","    data.append({\n","        'text': text,\n","        'label': 'Depression',\n","        'label_encoded': 0\n","    })\n","\n","# Add anxiety samples\n","for text in anxiety_texts:\n","    data.append({\n","        'text': text,\n","        'label': 'Anxiety',\n","        'label_encoded': 1\n","    })\n","\n","# Add neutral samples\n","for text in neutral_texts:\n","    data.append({\n","        'text': text,\n","        'label': 'Neutral',\n","        'label_encoded': 2\n","    })\n","\n","# Create DataFrame\n","df = pd.DataFrame(data)\n","\n","# Shuffle the data\n","df = df.sample(frac=1).reset_index(drop=True)\n","\n","# Save to CSV\n","df.to_csv('data/raw_data.csv', index=False)\n","\n","print(f\"Dataset created successfully!\")\n","print(f\"Total samples: {len(df)}\")\n","print(f\"Class distribution:\")\n","print(df['label'].value_counts())\n","print(f\"\\nFirst 5 rows:\")\n","print(df.head())"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import LabelEncoder\n","import pickle\n","import os\n","\n","# Download required NLTK data\n","try:\n","    nltk.data.find('tokenizers/punkt')\n","except LookupError:\n","    nltk.download('punkt')\n","\n","try:\n","    nltk.data.find('corpora/stopwords')\n","except LookupError:\n","    nltk.download('stopwords')\n","\n","try:\n","    nltk.data.find('corpora/wordnet')\n","except LookupError:\n","    nltk.download('wordnet')\n","\n","class TextPreprocessor:\n","    def __init__(self):\n","        self.stop_words = set(stopwords.words('english'))\n","        self.lemmatizer = WordNetLemmatizer()\n","        self.tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n","        self.label_encoder = LabelEncoder()\n","\n","    def clean_text(self, text):\n","        \"\"\"Clean and preprocess text\"\"\"\n","        # Convert to lowercase\n","        text = text.lower()\n","\n","        # Remove URLs\n","        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n","\n","        # Remove mentions and hashtags\n","        text = re.sub(r'@\\w+|#\\w+', '', text)\n","\n","        # Remove special characters and digits\n","        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n","\n","        # Remove extra whitespace\n","        text = re.sub(r'\\s+', ' ', text).strip()\n","\n","        return text\n","\n","    def tokenize_and_lemmatize(self, text):\n","        \"\"\"Tokenize and lemmatize text\"\"\"\n","        # Tokenize\n","        tokens = word_tokenize(text)\n","\n","        # Remove stopwords and lemmatize\n","        tokens = [\n","            self.lemmatizer.lemmatize(token)\n","            for token in tokens\n","            if token not in self.stop_words and len(token) > 2\n","        ]\n","\n","        return ' '.join(tokens)\n","\n","    def preprocess_dataset(self, df):\n","        \"\"\"Preprocess the entire dataset\"\"\"\n","        print(\"Starting text preprocessing...\")\n","\n","        # Clean text\n","        df['cleaned_text'] = df['text'].apply(self.clean_text)\n","\n","        # Tokenize and lemmatize\n","        df['processed_text'] = df['cleaned_text'].apply(self.tokenize_and_lemmatize)\n","\n","        # Remove empty texts\n","        df = df[df['processed_text'].str.len() > 0].reset_index(drop=True)\n","\n","        print(f\"Preprocessing completed. {len(df)} samples remaining.\")\n","\n","        return df\n","\n","    def fit_transform_features(self, texts):\n","        \"\"\"Fit TF-IDF vectorizer and transform texts\"\"\"\n","        print(\"Fitting TF-IDF vectorizer...\")\n","        X = self.tfidf.fit_transform(texts)\n","        print(f\"Feature matrix shape: {X.shape}\")\n","        return X\n","\n","    def transform_features(self, texts):\n","        \"\"\"Transform texts using fitted TF-IDF vectorizer\"\"\"\n","        return self.tfidf.transform(texts)\n","\n","    def fit_labels(self, labels):\n","        \"\"\"Fit label encoder\"\"\"\n","        return self.label_encoder.fit_transform(labels)\n","\n","    def transform_labels(self, labels):\n","        \"\"\"Transform labels using fitted encoder\"\"\"\n","        return self.label_encoder.transform(labels)\n","\n","    def inverse_transform_labels(self, encoded_labels):\n","        \"\"\"Convert encoded labels back to original labels\"\"\"\n","        return self.label_encoder.inverse_transform(encoded_labels)\n","\n","    def save_preprocessor(self, path='model/'):\n","        \"\"\"Save the fitted preprocessor objects\"\"\"\n","        os.makedirs(path, exist_ok=True)\n","\n","        # Save TF-IDF vectorizer\n","        with open(f'{path}/tfidf_vectorizer.pkl', 'wb') as f:\n","            pickle.dump(self.tfidf, f)\n","\n","        # Save label encoder\n","        with open(f'{path}/label_encoder.pkl', 'wb') as f:\n","            pickle.dump(self.label_encoder, f)\n","\n","        print(\"Preprocessor objects saved successfully!\")\n","\n","    def load_preprocessor(self, path='model/'):\n","        \"\"\"Load the fitted preprocessor objects\"\"\"\n","        # Load TF-IDF vectorizer\n","        with open(f'{path}/tfidf_vectorizer.pkl', 'rb') as f:\n","            self.tfidf = pickle.load(f)\n","\n","        # Load label encoder\n","        with open(f'{path}/label_encoder.pkl', 'rb') as f:\n","            self.label_encoder = pickle.load(f)\n","\n","        print(\"Preprocessor objects loaded successfully!\")\n","\n","def main():\n","    # Create directories\n","    os.makedirs('data', exist_ok=True)\n","    os.makedirs('model', exist_ok=True)\n","\n","    # Load data\n","    print(\"Loading dataset...\")\n","    df = pd.read_csv('data/raw_data.csv')\n","    print(f\"Loaded {len(df)} samples\")\n","\n","    # Initialize preprocessor\n","    preprocessor = TextPreprocessor()\n","\n","    # Preprocess dataset\n","    df_processed = preprocessor.preprocess_dataset(df)\n","\n","    # Fit and transform features\n","    X = preprocessor.fit_transform_features(df_processed['processed_text'])\n","\n","    # Fit and transform labels\n","    y = preprocessor.fit_labels(df_processed['label'])\n","\n","    # Save processed data\n","    df_processed.to_csv('data/processed_data.csv', index=False)\n","\n","    # Save preprocessor objects\n","    preprocessor.save_preprocessor()\n","\n","    print(\"\\nPreprocessing Summary:\")\n","    print(f\"- Original samples: {len(df)}\")\n","    print(f\"- Processed samples: {len(df_processed)}\")\n","    print(f\"- Feature dimensions: {X.shape[1]}\")\n","    print(f\"- Classes: {list(preprocessor.label_encoder.classes_)}\")\n","\n","    return X, y, preprocessor\n","\n","if __name__ == \"__main__\":\n","    X, y, preprocessor = main()"],"metadata":{"id":"vft_SH9phJUi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","from sklearn.metrics import precision_recall_fscore_support\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import joblib\n","import os\n","from data_preprocessing import TextPreprocessor\n","\n","class MentalHealthClassifier:\n","    def __init__(self):\n","        self.models = {\n","            'logistic_regression': LogisticRegression(random_state=42, max_iter=1000),\n","            'random_forest': RandomForestClassifier(random_state=42, n_estimators=100),\n","            'svm': SVC(random_state=42, probability=True)\n","        }\n","        self.best_model = None\n","        self.best_model_name = None\n","        self.preprocessor = TextPreprocessor()\n","\n","    def load_data(self):\n","        \"\"\"Load and preprocess data\"\"\"\n","        print(\"Loading preprocessed data...\")\n","\n","        # Load processed dataset\n","        df = pd.read_csv('data/processed_data.csv')\n","\n","        # Load preprocessor objects\n","        self.preprocessor.load_preprocessor()\n","\n","        # Transform features\n","        X = self.preprocessor.transform_features(df['processed_text'])\n","        y = df['label_encoded'].values\n","\n","        return X, y, df\n","\n","    def split_data(self, X, y, test_size=0.2, val_size=0.2):\n","        \"\"\"Split data into train, validation, and test sets\"\"\"\n","        # First split: train+val and test\n","        X_temp, X_test, y_temp, y_test = train_test_split(\n","            X, y, test_size=test_size, random_state=42, stratify=y\n","        )\n","\n","        # Second split: train and val\n","        val_size_adjusted = val_size / (1 - test_size)\n","        X_train, X_val, y_train, y_val = train_test_split(\n","            X_temp, y_temp, test_size=val_size_adjusted, random_state=42, stratify=y_temp\n","        )\n","\n","        print(f\"Data split completed:\")\n","        print(f\"- Training set: {X_train.shape[0]} samples\")\n","        print(f\"- Validation set: {X_val.shape[0]} samples\")\n","        print(f\"- Test set: {X_test.shape[0]} samples\")\n","\n","        return X_train, X_val, X_test, y_train, y_val, y_test\n","\n","    def train_models(self, X_train, y_train, X_val, y_val):\n","        \"\"\"Train multiple models and compare performance\"\"\"\n","        results = {}\n","\n","        print(\"\\nTraining models...\")\n","\n","        for name, model in self.models.items():\n","            print(f\"\\nTraining {name}...\")\n","\n","            # Train model\n","            model.fit(X_train, y_train)\n","\n","            # Predictions\n","            train_pred = model.predict(X_train)\n","            val_pred = model.predict(X_val)\n","\n","            # Calculate metrics\n","            train_acc = accuracy_score(y_train, train_pred)\n","            val_acc = accuracy_score(y_val, val_pred)\n","\n","            # Cross-validation score\n","            cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n","\n","            results[name] = {\n","                'model': model,\n","                'train_accuracy': train_acc,\n","                'val_accuracy': val_acc,\n","                'cv_mean': cv_scores.mean(),\n","                'cv_std': cv_scores.std(),\n","                'val_predictions': val_pred\n","            }\n","\n","            print(f\"- Training Accuracy: {train_acc:.4f}\")\n","            print(f\"- Validation Accuracy: {val_acc:.4f}\")\n","            print(f\"- CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n","\n","        return results\n","\n","    def select_best_model(self, results, X_val, y_val):\n","        \"\"\"Select the best performing model\"\"\"\n","        best_score = 0\n","        best_name = None\n","\n","        print(\"\\nModel Comparison:\")\n","        print(\"-\" * 60)\n","\n","        for name, result in results.items():\n","            val_acc = result['val_accuracy']\n","            print(f\"{name:20s}: {val_acc:.4f}\")\n","\n","            if val_acc > best_score:\n","                best_score = val_acc\n","                best_name = name\n","\n","        self.best_model = results[best_name]['model']\n","        self.best_model_name = best_name\n","\n","        print(f\"\\nBest model: {best_name} (Validation Accuracy: {best_score:.4f})\")\n","\n","        return self.best_model, best_name\n","\n","    def hyperparameter_tuning(self, X_train, y_train):\n","        \"\"\"Perform hyperparameter tuning on the best model\"\"\"\n","        print(f\"\\nPerforming hyperparameter tuning for {self.best_model_name}...\")\n","\n","        if self.best_model_name == 'logistic_regression':\n","            param_grid = {\n","                'C': [0.1, 1, 10, 100],\n","                'penalty': ['l1', 'l2'],\n","                'solver': ['liblinear']\n","            }\n","        elif self.best_model_name == 'random_forest':\n","            param_grid = {\n","                'n_estimators': [50, 100, 200],\n","                'max_depth': [None, 10, 20],\n","                'min_samples_split': [2, 5, 10]\n","            }\n","        elif self.best_model_name == 'svm':\n","            param_grid = {\n","                'C': [0.1, 1, 10],\n","                'kernel': ['rbf', 'linear'],\n","                'gamma': ['scale', 'auto']\n","            }\n","\n","        grid_search = GridSearchCV(\n","            self.best_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1\n","        )\n","\n","        grid_search.fit(X_train, y_train)\n","\n","        self.best_model = grid_search.best_estimator_\n","\n","        print(f\"Best parameters: {grid_search.best_params_}\")\n","        print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n","\n","    def evaluate_model(self, X_test, y_test):\n","        \"\"\"Evaluate the final model on test set\"\"\"\n","        print(\"\\nFinal Model Evaluation:\")\n","        print(\"=\" * 50)\n","\n","        # Predictions\n","        y_pred = self.best_model.predict(X_test)\n","        y_pred_proba = self.best_model.predict_proba(X_test)\n","\n","        # Accuracy\n","        test_acc = accuracy_score(y_test, y_pred)\n","        print(f\"Test Accuracy: {test_acc:.4f}\")\n","\n","        # Classification report\n","        class_names = self.preprocessor.label_encoder.classes_\n","        print(f\"\\nClassification Report:\")\n","        print(classification_report(y_test, y_pred, target_names=class_names))\n","\n","        # Confusion matrix\n","        cm = confusion_matrix(y_test, y_pred)\n","        self.plot_confusion_matrix(cm, class_names)\n","\n","        return y_pred, y_pred_proba\n","\n","    def plot_confusion_matrix(self, cm, class_names):\n","        \"\"\"Plot confusion matrix\"\"\"\n","        plt.figure(figsize=(8, 6))\n","        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","                   xticklabels=class_names, yticklabels=class_names)\n","        plt.title('Confusion Matrix')\n","        plt.ylabel('True Label')\n","        plt.xlabel('Predicted Label')\n","        plt.tight_layout()\n","        plt.savefig('model/confusion_matrix.png', dpi=300, bbox_inches='tight')\n","        plt.show()\n","\n","        print(\"Confusion matrix saved as 'model/confusion_matrix.png'\")\n","\n","    def save_model(self):\n","        \"\"\"Save the trained model\"\"\"\n","        model_path = 'model/mental_health_classifier.pkl'\n","        joblib.dump(self.best_model, model_path)\n","\n","        # Save model info\n","        model_info = {\n","            'model_name': self.best_model_name,\n","            'model_params': self.best_model.get_params(),\n","            'classes': list(self.preprocessor.label_encoder.classes_)\n","        }\n","\n","        joblib.dump(model_info, 'model/model_info.pkl')\n","\n","        print(f\"Model saved as '{model_path}'\")\n","        print(\"Model info saved as 'model/model_info.pkl'\")\n","\n","    def predict_single_text(self, text):\n","        \"\"\"Predict mental health category for a single text\"\"\"\n","        # Preprocess text\n","        cleaned_text = self.preprocessor.clean_text(text)\n","        processed_text = self.preprocessor.tokenize_and_lemmatize(cleaned_text)\n","\n","        # Transform to features\n","        X = self.preprocessor.transform_features([processed_text])\n","\n","        # Predict\n","        prediction = self.best_model.predict(X)[0]\n","        probabilities = self.best_model.predict_proba(X)[0]\n","\n","        # Convert to label\n","        predicted_label = self.preprocessor.inverse_transform_labels([prediction])[0]\n","\n","        # Create probability dictionary\n","        prob_dict = {}\n","        for i, class_name in enumerate(self.preprocessor.label_encoder.classes_):\n","            prob_dict[class_name] = probabilities[i]\n","\n","        return predicted_label, prob_dict\n","\n","def main():\n","    # Create directories\n","    os.makedirs('model', exist_ok=True)\n","\n","    # Initialize classifier\n","    classifier = MentalHealthClassifier()\n","\n","    # Load data\n","    X, y, df = classifier.load_data()\n","\n","    # Split data\n","    X_train, X_val, X_test, y_train, y_val, y_test = classifier.split_data(X, y)\n","\n","    # Train models\n","    results = classifier.train_models(X_train, y_train, X_val, y_val)\n","\n","    # Select best model\n","    best_model, best_name = classifier.select_best_model(results, X_val, y_val)\n","\n","    # Hyperparameter tuning\n","    classifier.hyperparameter_tuning(X_train, y_train)\n","\n","    # Final evaluation\n","    y_pred, y_pred_proba = classifier.evaluate_model(X_test, y_test)\n","\n","    # Save model\n","    classifier.save_model()\n","\n","    # Test single prediction\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"Testing Single Prediction:\")\n","    test_text = \"I feel so anxious about everything and can't stop worrying\"\n","    predicted_label, probabilities = classifier.predict_single_text(test_text)\n","\n","    print(f\"Text: '{test_text}'\")\n","    print(f\"Predicted: {predicted_label}\")\n","    print(\"Probabilities:\")\n","    for label, prob in probabilities.items():\n","        print(f\"  {label}: {prob:.4f}\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"0bUR8VDBhM4Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import streamlit as st\n","import pandas as pd\n","import numpy as np\n","import plotly.express as px\n","import plotly.graph_objects as go\n","from model_inference import MentalHealthPredictor\n","import os\n","import time\n","from datetime import datetime\n","\n","# Page configuration\n","st.set_page_config(\n","    page_title=\"Mental Health Chat Classifier\",\n","    page_icon=\"🧠\",\n","    layout=\"wide\",\n","    initial_sidebar_state=\"expanded\"\n",")\n","\n","# Custom CSS\n","st.markdown(\"\"\"\n","<style>\n","    .main-header {\n","        font-size: 3rem;\n","        color: #1f77b4;\n","        text-align: center;\n","        margin-bottom: 2rem;\n","    }\n","    .subheader {\n","        font-size: 1.5rem;\n","        color: #333;\n","        margin-bottom: 1rem;\n","    }\n","    .prediction-box {\n","        padding: 1rem;\n","        border-radius: 10px;\n","        margin: 1rem 0;\n","    }\n","    .depression {\n","        background-color: #ffebee;\n","        border-left: 5px solid #f44336;\n","    }\n","    .anxiety {\n","        background-color: #fff3e0;\n","        border-left: 5px solid #ff9800;\n","    }\n","    .neutral {\n","        background-color: #e8f5e8;\n","        border-left: 5px solid #4caf50;\n","    }\n","    .confidence-high {\n","        color: #4caf50;\n","        font-weight: bold;\n","    }\n","    .confidence-medium {\n","        color: #ff9800;\n","        font-weight: bold;\n","    }\n","    .confidence-low {\n","        color: #f44336;\n","        font-weight: bold;\n","    }\n","</style>\n","\"\"\", unsafe_allow_html=True)\n","\n","@st.cache_resource\n","def load_predictor():\n","    \"\"\"Load the model predictor (cached for performance)\"\"\"\n","    try:\n","        return MentalHealthPredictor()\n","    except Exception as e:\n","        st.error(f\"Error loading model: {str(e)}\")\n","        st.error(\"Please make sure you have trained the model by running train_model.py first\")\n","        return None\n","\n","def get_confidence_class(confidence):\n","    \"\"\"Get CSS class based on confidence level\"\"\"\n","    if confidence >= 0.7:\n","        return \"confidence-high\"\n","    elif confidence >= 0.5:\n","        return \"confidence-medium\"\n","    else:\n","        return \"confidence-low\"\n","\n","def create_probability_chart(probabilities):\n","    \"\"\"Create a probability visualization chart\"\"\"\n","    labels = list(probabilities.keys())\n","    values = list(probabilities.values())\n","\n","    fig = go.Figure(data=[\n","        go.Bar(\n","            x=labels,\n","            y=values,\n","            marker_color=['#f44336', '#ff9800', '#4caf50'],\n","            text=[f'{v:.2%}' for v in values],\n","            textposition='auto',\n","        )\n","    ])\n","\n","    fig.update_layout(\n","        title=\"Class Probabilities\",\n","        xaxis_title=\"Mental Health Categories\",\n","        yaxis_title=\"Probability\",\n","        yaxis=dict(range=[0, 1]),\n","        height=400,\n","        showlegend=False\n","    )\n","\n","    return fig\n","\n","def main():\n","    # Header\n","    st.markdown('<h1 class=\"main-header\">🧠 Mental Health Chat Classifier</h1>', unsafe_allow_html=True)\n","\n","    st.markdown(\"\"\"\n","    <div style=\"text-align: center; margin-bottom: 2rem;\">\n","        <p style=\"font-size: 1.2rem; color: #666;\">\n","        Analyze chat messages to identify potential mental health indicators\n","        </p>\n","        <p style=\"font-size: 1rem; color: #888;\">\n","        <strong>Categories:</strong> Depression, Anxiety, Neutral\n","        </p>\n","    </div>\n","    \"\"\", unsafe_allow_html=True)\n","\n","    # Load predictor\n","    predictor = load_predictor()\n","\n","    if predictor is None:\n","        st.stop()\n","\n","    # Sidebar\n","    st.sidebar.title(\"📊 About\")\n","    st.sidebar.info(\"\"\"\n","    This app uses machine learning to classify chat messages into mental health categories:\n","\n","    🔴 **Depression**: Signs of sadness, hopelessness, or low mood\n","\n","    🟠 **Anxiety**: Signs of worry, panic, or nervousness\n","\n","    🟢 **Neutral**: Normal conversation without mental health indicators\n","\n","    **Note**: This tool is for educational purposes only and should not replace professional mental health advice.\n","    \"\"\")\n","\n","    # Model info\n","    if hasattr(predictor, 'model_info') and predictor.model_info:\n","        st.sidebar.subheader(\"🤖 Model Info\")\n","        st.sidebar.write(f\"**Algorithm**: {predictor.model_info['model_name'].replace('_', ' ').title()}\")\n","        st.sidebar.write(f\"**Classes**: {len(predictor.model_info['classes'])}\")\n","\n","    # Main content\n","    col1, col2 = st.columns([2, 1])\n","\n","    with col1:\n","        st.subheader(\"💬 Enter Your Message\")\n","\n","        # Text input options\n","        input_method = st.radio(\"Choose input method:\", [\"Single Message\", \"Multiple Messages\"])\n","\n","        if input_method == \"Single Message\":\n","            # Single text input\n","            user_input = st.text_area(\n","                \"Type your message here:\",\n","                height=150,\n","                placeholder=\"e.g., I feel really anxious about my upcoming presentation and can't stop worrying about it...\"\n","            )\n","\n","            # Analyze button\n","            if st.button(\"🔍 Analyze Message\", type=\"primary\"):\n","                if user_input.strip():\n","                    with st.spinner(\"Analyzing message...\"):\n","                        result = predictor.predict(user_input)\n","\n","                    if result['error']:\n","                        st.error(f\"Error: {result['error']}\")\n","                    else:\n","                        # Display results\n","                        st.subheader(\"📋 Analysis Results\")\n","\n","                        # Main prediction\n","                        predicted_class = result['predicted_class']\n","                        confidence = result['confidence']\n","\n","                        # Prediction box with styling\n","                        box_class = predicted_class.lower()\n","                        confidence_class = get_confidence_class(confidence)\n","\n","                        st.markdown(f\"\"\"\n","                        <div class=\"prediction-box {box_class}\">\n","                            <h3>Predicted Category: {predicted_class}</h3>\n","                            <p class=\"{confidence_class}\">Confidence: {confidence:.2%}</p>\n","                        </div>\n","                        \"\"\", unsafe_allow_html=True)\n","\n","                        # Probability chart\n","                        fig = create_probability_chart(result['probabilities'])\n","                        st.plotly_chart(fig, use_container_width=True)\n","\n","                        # Feature analysis\n","                        with st.expander(\"🔬 Feature Analysis\"):\n","                            analysis = predictor.analyze_text_features(user_input)\n","                            if 'error' not in analysis:\n","                                st.write(\"**Top contributing words/phrases:**\")\n","                                for i, feature in enumerate(analysis['top_features'][:10], 1):\n","                                    st.write(f\"{i}. **{feature['feature']}** (Score: {feature['tfidf_score']:.3f})\")\n","                else:\n","                    st.warning(\"Please enter a message to analyze.\")\n","\n","        else:\n","            # Multiple text input\n","            st.subheader(\"📝 Batch Analysis\")\n","\n","            # Text area for multiple messages\n","            multiple_input = st.text_area(\n","                \"Enter multiple messages (one per line):\",\n","                height=200,\n","                placeholder=\"I feel so anxious about everything\\nHad a great day today\\nI can't get out of bed anymore\"\n","            )\n","\n","            if st.button(\"🔍 Analyze All Messages\", type=\"primary\"):\n","                if multiple_input.strip():\n","                    messages = [msg.strip() for msg in multiple_input.split('\\n') if msg.strip()]\n","\n","                    if messages:\n","                        with st.spinner(f\"Analyzing {len(messages)} messages...\"):\n","                            results = predictor.predict_batch(messages)\n","\n","                        # Display batch results\n","                        st.subheader(\"📊 Batch Analysis Results\")\n","\n","                        # Summary statistics\n","                        valid_results = [r for r in results if not r['error']]\n","                        if valid_results:\n","                            categories = [r['predicted_class'] for r in valid_results]\n","                            category_counts = pd.Series(categories).value_counts()\n","\n","                            # Category distribution chart\n","                            fig_pie = px.pie(\n","                                values=category_counts.values,\n","                                names=category_counts.index,\n","                                title=\"Distribution of Predicted Categories\",\n","                                color_discrete_map={\n","                                    'Depression': '#f44336',\n","                                    'Anxiety': '#ff9800',\n","                                    'Neutral': '#4caf50'\n","                                }\n","                            )\n","                            st.plotly_chart(fig_pie, use_container_width=True)\n","\n","                            # Detailed results table\n","                            st.subheader(\"📋 Detailed Results\")\n","                            results_df = []\n","                            for i, result in enumerate(results, 1):\n","                                if result['error']:\n","                                    results_df.append({\n","                                        'Message #': i,\n","                                        'Text': result.get('original_text', 'N/A')[:50] + '...',\n","                                        'Prediction': 'Error',\n","                                        'Confidence': 0,\n","                                        'Error': result['error']\n","                                    })\n","                                else:\n","                                    results_df.append({\n","                                        'Message #': i,\n","                                        'Text': result['original_text'][:50] + '...',\n","                                        'Prediction': result['predicted_class'],\n","                                        'Confidence': f\"{result['confidence']:.2%}\",\n","                                        'Error': None\n","                                    })\n","\n","                            df = pd.DataFrame(results_df)\n","                            st.dataframe(df, use_container_width=True)\n","                        else:\n","                            st.error(\"No valid messages could be processed.\")\n","                    else:\n","                        st.warning(\"Please enter at least one message.\")\n","                else:\n","                    st.warning(\"Please enter messages to analyze.\")\n","\n","    with col2:\n","        st.subheader(\"📈 Quick Stats\")\n","\n","        # Sample predictions for demo\n","        sample_texts = [\n","            \"I feel anxious about my presentation\",\n","            \"Having a wonderful day today\",\n","            \"I feel hopeless and empty inside\"\n","        ]\n","\n","        if st.button(\"🎲 Try Sample Predictions\"):\n","            st.subheader(\"Sample Analysis\")\n","            for i, text in enumerate(sample_texts, 1):\n","                result = predictor.predict(text)\n","                if not result['error']:\n","                    st.write(f\"**{i}.** _{text}_\")\n","                    st.write(f\"→ **{result['predicted_class']}** ({result['confidence']:.1%})\")\n","                    st.write(\"---\")\n","\n","        # Tips section\n","        st.subheader(\"💡 Tips for Better Results\")\n","        st.info(\"\"\"\n","        - Use complete sentences\n","        - Include emotional context\n","        - Be specific about feelings\n","        - Avoid very short messages\n","        - Use natural language\n","        \"\"\")\n","\n","        # Warning\n","        st.warning(\"\"\"\n","        ⚠️ **Disclaimer**: This tool is for educational purposes only.\n","\n","        If you're experiencing mental health issues, please consult with a qualified mental health professional.\n","\n","        🆘 **Crisis Resources:**\n","        - National Suicide Prevention Lifeline: 988\n","        - Crisis Text Line: Text HOME to 741741\n","        \"\"\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"kWfc-eANhRql"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mental Health Chat Classifier - Training Notebook\n","\n","# Cell 1: Import Libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Set style for plots\n","plt.style.use('seaborn-v0_8')\n","sns.set_palette(\"husl\")\n","\n","print(\"Libraries imported successfully!\")\n","\n","# Cell 2: Generate Sample Data\n","import sys\n","sys.path.append('.')\n","from generate_sample_data import *\n","\n","# Generate sample data\n","exec(open('generate_sample_data.py').read())\n","print(\"Sample data generated!\")\n","\n","# Cell 3: Load and Explore Data\n","# Load the generated dataset\n","df = pd.read_csv('data/raw_data.csv')\n","\n","print(\"Dataset Overview:\")\n","print(f\"Shape: {df.shape}\")\n","print(f\"\\nColumns: {df.columns.tolist()}\")\n","print(f\"\\nClass Distribution:\")\n","print(df['label'].value_counts())\n","\n","# Display sample texts\n","print(\"\\nSample texts by category:\")\n","for label in df['label'].unique():\n","    print(f\"\\n{label} examples:\")\n","    samples = df[df['label'] == label]['text'].head(3)\n","    for i, text in enumerate(samples, 1):\n","        print(f\"  {i}. {text}\")\n","\n","# Cell 4: Data Visualization\n","fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n","\n","# Class distribution\n","df['label'].value_counts().plot(kind='bar', ax=axes[0,0], color=['#ff6b6b', '#4ecdc4', '#45b7d1'])\n","axes[0,0].set_title('Class Distribution')\n","axes[0,0].set_xlabel('Mental Health Category')\n","axes[0,0].set_ylabel('Count')\n","axes[0,0].tick_params(axis='x', rotation=45)\n","\n","# Text length distribution\n","df['text_length'] = df['text'].str.len()\n","df.boxplot(column='text_length', by='label', ax=axes[0,1])\n","axes[0,1].set_title('Text Length Distribution by Category')\n","axes[0,1].set_xlabel('Mental Health Category')\n","axes[0,1].set_ylabel('Text Length (characters)')\n","\n","# Word count distribution\n","df['word_count'] = df['text'].str.split().str.len()\n","for label in df['label'].unique():\n","    data = df[df['label'] == label]['word_count']\n","    axes[1,0].hist(data, alpha=0.7, label=label, bins=10)\n","axes[1,0].set_title('Word Count Distribution')\n","axes[1,0].set_xlabel('Number of Words')\n","axes[1,0].set_ylabel('Frequency')\n","axes[1,0].legend()\n","\n","# Label encoding distribution\n","df['label_encoded'].value_counts().plot(kind='pie', ax=axes[1,1], autopct='%1.1f%%')\n","axes[1,1].set_title('Label Encoding Distribution')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Cell 5: Text Preprocessing\n","from data_preprocessing import TextPreprocessor\n","\n","# Initialize preprocessor\n","preprocessor = TextPreprocessor()\n","\n","# Preprocess the dataset\n","df_processed = preprocessor.preprocess_dataset(df.copy())\n","\n","print(\"Preprocessing completed!\")\n","print(f\"Original text example: '{df.iloc[0]['text']}'\")\n","print(f\"Cleaned text: '{df_processed.iloc[0]['cleaned_text']}'\")\n","print(f\"Processed text: '{df_processed.iloc[0]['processed_text']}'\")\n","\n","# Cell 6: Feature Engineering\n","# Fit TF-IDF vectorizer\n","X = preprocessor.fit_transform_features(df_processed['processed_text'])\n","y = preprocessor.fit_labels(df_processed['label'])\n","\n","print(f\"Feature matrix shape: {X.shape}\")\n","print(f\"Number of unique features: {X.shape[1]}\")\n","print(f\"Sparsity: {(1.0 - X.nnz / (X.shape[0] * X.shape[1])) * 100:.2f}%\")\n","\n","# Show top TF-IDF features\n","feature_names = preprocessor.tfidf.get_feature_names_out()\n","tfidf_scores = X.mean(axis=0).A1\n","top_features = sorted(zip(feature_names, tfidf_scores), key=lambda x: x[1], reverse=True)\n","\n","print(\"\\nTop 20 TF-IDF features:\")\n","for i, (feature, score) in enumerate(top_features[:20], 1):\n","    print(f\"{i:2d}. {feature:15s}: {score:.4f}\")\n","\n","# Cell 7: Train-Test Split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42, stratify=y\n",")\n","\n","print(f\"Training set: {X_train.shape[0]} samples\")\n","print(f\"Test set: {X_test.shape[0]} samples\")\n","\n","# Check class distribution in splits\n","train_labels = preprocessor.inverse_transform_labels(y_train)\n","test_labels = preprocessor.inverse_transform_labels(y_test)\n","\n","print(f\"\\nTraining set distribution:\")\n","print(pd.Series(train_labels).value_counts())\n","print(f\"\\nTest set distribution:\")\n","print(pd.Series(test_labels).value_counts())\n","\n","# Cell 8: Model Training and Comparison\n","models = {\n","    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n","    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n","    'SVM': SVC(random_state=42, probability=True)\n","}\n","\n","results = {}\n","\n","print(\"Training and evaluating models...\")\n","print(\"=\" * 50)\n","\n","for name, model in models.items():\n","    print(f\"\\nTraining {name}...\")\n","\n","    # Train model\n","    model.fit(X_train, y_train)\n","\n","    # Predictions\n","    train_pred = model.predict(X_train)\n","    test_pred = model.predict(X_test)\n","\n","    # Calculate metrics\n","    train_acc = accuracy_score(y_train, train_pred)\n","    test_acc = accuracy_score(y_test, test_pred)\n","\n","    # Cross-validation\n","    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n","\n","    results[name] = {\n","        'model': model,\n","        'train_accuracy': train_acc,\n","        'test_accuracy': test_acc,\n","        'cv_mean': cv_scores.mean(),\n","        'cv_std': cv_scores.std(),\n","        'test_predictions': test_pred\n","    }\n","\n","    print(f\"  Training Accuracy: {train_acc:.4f}\")\n","    print(f\"  Test Accuracy: {test_acc:.4f}\")\n","    print(f\"  CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n","\n","# Cell 9: Model Comparison Visualization\n","# Create comparison DataFrame\n","comparison_df = pd.DataFrame({\n","    'Model': list(results.keys()),\n","    'Training Accuracy': [results[name]['train_accuracy'] for name in results.keys()],\n","    'Test Accuracy': [results[name]['test_accuracy'] for name in results.keys()],\n","    'CV Mean': [results[name]['cv_mean'] for name in results.keys()],\n","    'CV Std': [results[name]['cv_std'] for name in results.keys()]\n","})\n","\n","print(\"\\nModel Comparison:\")\n","print(comparison_df.round(4))\n","\n","# Visualization\n","fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n","\n","# Accuracy comparison\n","x = np.arange(len(results))\n","width = 0.25\n","\n","axes[0].bar(x - width, comparison_df['Training Accuracy'], width, label='Training', alpha=0.8)\n","axes[0].bar(x, comparison_df['Test Accuracy'], width, label='Test', alpha=0.8)\n","axes[0].bar(x + width, comparison_df['CV Mean'], width, label='CV Mean', alpha=0.8)\n","\n","axes[0].set_xlabel('Models')\n","axes[0].set_ylabel('Accuracy')\n","axes[0].set_title('Model Performance Comparison')\n","axes[0].set_xticks(x)\n","axes[0].set_xticklabels(comparison_df['Model'], rotation=45)\n","axes[0].legend()\n","axes[0].grid(True, alpha=0.3)\n","\n","# CV scores with error bars\n","axes[1].bar(comparison_df['Model'], comparison_df['CV Mean'],\n","           yerr=comparison_df['CV Std'], capsize=5, alpha=0.8)\n","axes[1].set_ylabel('Cross-Validation Accuracy')\n","axes[1].set_title('Cross-Validation Performance')\n","axes[1].tick_params(axis='x', rotation=45)\n","axes[1].grid(True, alpha=0.3)\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Cell 10: Select Best Model and Hyperparameter Tuning\n","# Select best model based on test accuracy\n","best_model_name = max(results.keys(), key=lambda x: results[x]['test_accuracy'])\n","best_model = results[best_model_name]['model']\n","\n","print(f\"Best performing model: {best_model_name}\")\n","print(f\"Test accuracy: {results[best_model_name]['test_accuracy']:.4f}\")\n","\n","# Hyperparameter tuning for the best model\n","print(f\"\\nPerforming hyperparameter tuning for {best_model_name}...\")\n","\n","if best_model_name == 'Logistic Regression':\n","    param_grid = {\n","        'C': [0.1, 1, 10, 100],\n","        'penalty': ['l1', 'l2'],\n","        'solver': ['liblinear']\n","    }\n","elif best_model_name == 'Random Forest':\n","    param_grid = {\n","        'n_estimators': [50, 100, 200],\n","        'max_depth': [None, 10, 20],\n","        'min_samples_split': [2, 5, 10]\n","    }\n","elif best_model_name == 'SVM':\n","    param_grid = {\n","        'C': [0.1, 1, 10],\n","        'kernel': ['rbf', 'linear'],\n","        'gamma': ['scale', 'auto']\n","    }\n","\n","# Grid search\n","grid_search = GridSearchCV(\n","    best_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1\n",")\n","\n","grid_search.fit(X_train, y_train)\n","\n","print(f\"Best parameters: {grid_search.best_params_}\")\n","print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n","\n","# Update best model\n","best_model_tuned = grid_search.best_estimator_\n","\n","# Cell 11: Final Model Evaluation\n","print(\"Final Model Evaluation\")\n","print(\"=\" * 50)\n","\n","# Predictions with tuned model\n","y_pred = best_model_tuned.predict(X_test)\n","y_pred_proba = best_model_tuned.predict_proba(X_test)\n","\n","# Accuracy\n","final_accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Final Test Accuracy: {final_accuracy:.4f}\")\n","\n","# Classification report\n","class_names = preprocessor.label_encoder.classes_\n","print(f\"\\nClassification Report:\")\n","print(classification_report(y_test, y_pred, target_names=class_names))\n","\n","# Confusion matrix\n","cm = confusion_matrix(y_test, y_pred)\n","print(f\"\\nConfusion Matrix:\")\n","print(cm)\n","\n","# Cell 12: Confusion Matrix Visualization\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","           xticklabels=class_names, yticklabels=class_names)\n","plt.title('Confusion Matrix - Final Model')\n","plt.ylabel('True Label')\n","plt.xlabel('Predicted Label')\n","plt.show()\n","\n","# Detailed confusion matrix analysis\n","print(\"\\nConfusion Matrix Analysis:\")\n","for i, true_class in enumerate(class_names):\n","    for j, pred_class in enumerate(class_names):\n","        count = cm[i, j]\n","        if i == j:\n","            print(f\"✓ Correctly classified {true_class}: {count} samples\")\n","        else:\n","            print(f\"✗ {true_class} misclassified as {pred_class}: {count} samples\")\n","\n","# Cell 13: Feature Importance Analysis\n","if hasattr(best_model_tuned, 'coef_'):\n","    # For linear models (Logistic Regression, SVM with linear kernel)\n","    feature_importance = np.abs(best_model_tuned.coef_).mean(axis=0)\n","elif hasattr(best_model_tuned, 'feature_importances_'):\n","    # For tree-based models (Random Forest)\n","    feature_importance = best_model_tuned.feature_importances_\n","else:\n","    feature_importance = None\n","\n","if feature_importance is not None:\n","    # Get feature names\n","    feature_names = preprocessor.tfidf.get_feature_names_out()\n","\n","    # Create feature importance DataFrame\n","    feature_df = pd.DataFrame({\n","        'feature': feature_names,\n","        'importance': feature_importance\n","    }).sort_values('importance', ascending=False)\n","\n","    print(\"Top 20 Most Important Features:\")\n","    print(feature_df.head(20))\n","\n","    # Plot top features\n","    plt.figure(figsize=(12, 8))\n","    top_features = feature_df.head(15)\n","    plt.barh(range(len(top_features)), top_features['importance'])\n","    plt.yticks(range(len(top_features)), top_features['feature'])\n","    plt.xlabel('Feature Importance')\n","    plt.title('Top 15 Most Important Features')\n","    plt.gca().invert_yaxis()\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Cell 14: Prediction Examples\n","print(\"Prediction Examples on Test Set:\")\n","print(\"=\" * 50)\n","\n","# Get original text for test samples\n","test_indices = X_test.nonzero()[0][:5]  # First 5 test samples\n","test_texts = df_processed.iloc[test_indices]['text'].values\n","test_true_labels = preprocessor.inverse_transform_labels(y_test[:5])\n","test_pred_labels = preprocessor.inverse_transform_labels(y_pred[:5])\n","test_probabilities = y_pred_proba[:5]\n","\n","for i in range(5):\n","    print(f\"\\nExample {i+1}:\")\n","    print(f\"Text: '{test_texts[i][:100]}{'...' if len(test_texts[i]) > 100 else ''}'\")\n","    print(f\"True Label: {test_true_labels[i]}\")\n","    print(f\"Predicted: {test_pred_labels[i]}\")\n","    print(f\"Probabilities:\")\n","    for j, class_name in enumerate(class_names):\n","        print(f\"  {class_name}: {test_probabilities[i][j]:.3f}\")\n","    print(\"-\" * 40)\n","\n","# Cell 15: Save Model and Preprocessor\n","import os\n","import joblib\n","\n","# Create model directory\n","os.makedirs('model', exist_ok=True)\n","\n","# Save model\n","joblib.dump(best_model_tuned, 'model/mental_health_classifier.pkl')\n","\n","# Save preprocessor components\n","preprocessor.save_preprocessor('model/')\n","\n","# Save model info\n","model_info = {\n","    'model_name': best_model_name.lower().replace(' ', '_'),\n","    'model_params': best_model_tuned.get_params(),\n","    'classes': list(class_names),\n","    'final_accuracy': final_accuracy,\n","    'best_cv_score': grid_search.best_score_,\n","    'feature_count': X_train.shape[1]\n","}\n","\n","joblib.dump(model_info, 'model/model_info.pkl')\n","\n","print(\"Model and preprocessor saved successfully!\")\n","print(f\"Model accuracy: {final_accuracy:.4f}\")\n","print(f\"Model type: {best_model_name}\")\n","print(f\"Feature count: {X_train.shape[1]}\")\n","\n","# Cell 16: Test Inference Pipeline\n","from model_inference import MentalHealthPredictor\n","\n","# Test the complete inference pipeline\n","print(\"Testing Inference Pipeline:\")\n","print(\"=\" * 30)\n","\n","try:\n","    predictor = MentalHealthPredictor()\n","\n","    # Test examples\n","    test_examples = [\n","        \"I feel so anxious about my upcoming presentation and can't stop worrying\",\n","        \"Had an amazing day with friends, feeling really positive\",\n","        \"I can't get out of bed and feel completely hopeless about everything\"\n","    ]\n","\n","    for i, text in enumerate(test_examples, 1):\n","        result = predictor.predict(text)\n","        print(f\"\\nTest {i}:\")\n","        print(f\"Text: '{text}'\")\n","        if result['error']:\n","            print(f\"Error: {result['error']}\")\n","        else:\n","            print(f\"Predicted: {result['predicted_class']}\")\n","            print(f\"Confidence: {result['confidence']:.2%}\")\n","            print(\"Probabilities:\")\n","            for label, prob in result['probabilities'].items():\n","                print(f\"  {label}: {prob:.3f}\")\n","\n","    print(\"\\n✓ Inference pipeline working correctly!\")\n","\n","except Exception as e:\n","    print(f\"✗ Error in inference pipeline: {e}\")\n","\n","# Cell 17: Model Summary and Next Steps\n","print(\"\\n\" + \"=\"*60)\n","print(\"🧠 MENTAL HEALTH CHAT CLASSIFIER - TRAINING COMPLETE\")\n","print(\"=\"*60)\n","\n","print(f\"\\n📊 FINAL RESULTS:\")\n","print(f\"   • Model Type: {best_model_name}\")\n","print(f\"   • Test Accuracy: {final_accuracy:.2%}\")\n","print(f\"   • Cross-Validation Score: {grid_search.best_score_:.2%}\")\n","print(f\"   • Feature Count: {X_train.shape[1]}\")\n","print(f\"   • Training Samples: {X_train.shape[0]}\")\n","print(f\"   • Test Samples: {X_test.shape[0]}\")\n","\n","print(f\"\\n🎯 CLASS PERFORMANCE:\")\n","# Calculate per-class metrics\n","for i, class_name in enumerate(class_names):\n","    class_mask = (y_test == i)\n","    class_pred_mask = (y_pred == i)\n","\n","    # True positives, false positives, false negatives\n","    tp = np.sum((y_test == i) & (y_pred == i))\n","    fp = np.sum((y_test != i) & (y_pred == i))\n","    fn = np.sum((y_test == i) & (y_pred != i))\n","\n","    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n","    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n","    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n","\n","    print(f\"   • {class_name:10s}: Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}\")\n","\n","print(f\"\\n📁 SAVED FILES:\")\n","print(f\"   • model/mental_health_classifier.pkl\")\n","print(f\"   • model/tfidf_vectorizer.pkl\")\n","print(f\"   • model/label_encoder.pkl\")\n","print(f\"   • model/model_info.pkl\")\n","print(f\"   • data/processed_data.csv\")\n","\n","print(f\"\\n🚀 NEXT STEPS:\")\n","print(f\"   1. Run the Streamlit app: streamlit run app.py\")\n","print(f\"   2. Test with your own text samples\")\n","print(f\"   3. Deploy to Streamlit Cloud or other platforms\")\n","print(f\"   4. Collect more data to improve performance\")\n","print(f\"   5. Try advanced models (BERT, RoBERTa)\")\n","\n","print(f\"\\n⚠️  IMPORTANT REMINDERS:\")\n","print(f\"   • This is for educational purposes only\")\n","print(f\"   • Not a substitute for professional mental health care\")\n","print(f\"   • Always include appropriate disclaimers in deployment\")\n","\n","print(\"\\n✨ Training notebook completed successfully! ✨\")"],"metadata":{"id":"nfU7nOlEhXzv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!/usr/bin/env python3\n","\"\"\"\n","Mental Health Chat Classifier - Complete Pipeline Runner\n","\n","This script runs the entire pipeline from data generation to model training.\n","Perfect for setting up the project from scratch.\n","\n","Usage:\n","    python run_pipeline.py [--skip-data] [--quick-train]\n","\n","Arguments:\n","    --skip-data: Skip data generation if data already exists\n","    --quick-train: Use faster training settings (fewer CV folds, smaller grid search)\n","\"\"\"\n","\n","import os\n","import sys\n","import argparse\n","import time\n","from datetime import datetime\n","\n","def print_banner():\n","    \"\"\"Print project banner\"\"\"\n","    banner = \"\"\"\n","    ╔══════════════════════════════════════════════════════════╗\n","    ║              🧠 Mental Health Chat Classifier             ║\n","    ║                     Pipeline Runner                      ║\n","    ╚══════════════════════════════════════════════════════════╝\n","    \"\"\"\n","    print(banner)\n","\n","def print_step(step_num, step_name, description=\"\"):\n","    \"\"\"Print formatted step information\"\"\"\n","    print(f\"\\n{'='*60}\")\n","    print(f\"STEP {step_num}: {step_name.upper()}\")\n","    if description:\n","        print(f\"Description: {description}\")\n","    print(f\"{'='*60}\")\n","\n","def check_dependencies():\n","    \"\"\"Check if all required packages are installed\"\"\"\n","    print_step(0, \"Dependency Check\", \"Verifying required packages are installed\")\n","\n","    required_packages = [\n","        'pandas', 'numpy', 'scikit-learn', 'nltk',\n","        'matplotlib', 'seaborn', 'joblib', 'streamlit'\n","    ]\n","\n","    missing_packages = []\n","\n","    for package in required_packages:\n","        try:\n","            __import__(package)\n","            print(f\"✓ {package}\")\n","        except ImportError:\n","            missing_packages.append(package)\n","            print(f\"✗ {package}\")\n","\n","    if missing_packages:\n","        print(f\"\\n❌ Missing packages: {', '.join(missing_packages)}\")\n","        print(\"Please install them using: pip install -r requirements.txt\")\n","        return False\n","\n","    print(\"\\n✅ All dependencies satisfied!\")\n","    return True\n","\n","def create_directories():\n","    \"\"\"Create necessary directories\"\"\"\n","    print_step(1, \"Setup\", \"Creating project directories\")\n","\n","    directories = ['data', 'model', 'notebooks']\n","\n","    for directory in directories:\n","        os.makedirs(directory, exist_ok=True)\n","        print(f\"✓ Created/verified directory: {directory}/\")\n","\n","    print(\"✅ Directory structure ready!\")\n","\n","def generate_data(skip_if_exists=False):\n","    \"\"\"Generate sample dataset\"\"\"\n","    print_step(2, \"Data Generation\", \"Creating sample mental health text dataset\")\n","\n","    if skip_if_exists and os.path.exists('data/raw_data.csv'):\n","        print(\"⏭️  Data already exists, skipping generation...\")\n","        return True\n","\n","    try:\n","        print(\"📝 Generating sample mental health text data...\")\n","        exec(open('generate_sample_data.py').read())\n","\n","        # Verify data was created\n","        if os.path.exists('data/raw_data.csv'):\n","            import pandas as pd\n","            df = pd.read_csv('data/raw_data.csv')\n","            print(f\"✅ Dataset created successfully!\")\n","            print(f\"   • Total samples: {len(df)}\")\n","            print(f\"   • Classes: {df['label'].unique().tolist()}\")\n","            print(f\"   • Distribution: {dict(df['label'].value_counts())}\")\n","            return True\n","        else:\n","            print(\"❌ Failed to create dataset file\")\n","            return False\n","\n","    except Exception as e:\n","        print(f\"❌ Error generating data: {str(e)}\")\n","        return False\n","\n","def preprocess_data():\n","    \"\"\"Preprocess the generated data\"\"\"\n","    print_step(3, \"Data Preprocessing\", \"Cleaning and preparing text data\")\n","\n","    try:\n","        print(\"🧹 Cleaning and preprocessing text data...\")\n","        from data_preprocessing import main as preprocess_main\n","        X, y, preprocessor = preprocess_main()\n","\n","        print(\"✅ Data preprocessing completed!\")\n","        print(f\"   • Feature matrix shape: {X.shape}\")\n","        print(f\"   • Processed samples: {len(y)}\")\n","        print(f\"   • Feature count: {X.shape[1]}\")\n","\n","        return True\n","\n","    except Exception as e:\n","        print(f\"❌ Error in preprocessing: {str(e)}\")\n","        return False\n","\n","def train_model(quick_mode=False):\n","    \"\"\"Train the machine learning model\"\"\"\n","    print_step(4, \"Model Training\", \"Training and evaluating ML models\")\n","\n","    try:\n","        print(\"🤖 Training machine learning models...\")\n","\n","        if quick_mode:\n","            print(\"⚡ Quick training mode enabled - faster but less thorough\")\n","\n","        # Import and run training\n","        from train_model import main as train_main\n","        train_main()\n","\n","        # Verify model was saved\n","        if os.path.exists('model/mental_health_classifier.pkl'):\n","            print(\"✅ Model training completed successfully!\")\n","\n","            # Load and display model info\n","            import joblib\n","            model_info = joblib.load('model/model_info.pkl')\n","            print(f\"   • Best model: {model_info['model_name']}\")\n","            print(f\"   • Test accuracy: {model_info['final_accuracy']:.2%}\")\n","            print(f\"   • Feature count: {model_info['feature_count']}\")\n","\n","            return True\n","        else:\n","            print(\"❌ Model file not found after training\")\n","            return False\n","\n","    except Exception as e:\n","        print(f\"❌ Error in model training: {str(e)}\")\n","        return False\n","\n","def test_inference():\n","    \"\"\"Test the model inference pipeline\"\"\"\n","    print_step(5, \"Inference Testing\", \"Testing model prediction capabilities\")\n","\n","    try:\n","        print(\"🧪 Testing model inference pipeline...\")\n","\n","        from model_inference import MentalHealthPredictor\n","\n","        # Initialize predictor\n","        predictor = MentalHealthPredictor()\n","\n","        # Test examples\n","        test_examples = [\n","            \"I feel so anxious and worried about everything\",\n","            \"Having a wonderful day with friends today\",\n","            \"I feel hopeless and can't find any motivation\"\n","        ]\n","\n","        print(\"\\n📋 Test Predictions:\")\n","        for i, text in enumerate(test_examples, 1):\n","            result = predictor.predict(text)\n","            if result['error']:\n","                print(f\"   {i}. Error: {result['error']}\")\n","                return False\n","            else:\n","                print(f\"   {i}. '{text[:40]}...'\")\n","                print(f\"      → {result['predicted_class']} ({result['confidence']:.1%})\")\n","\n","        print(\"\\n✅ Inference pipeline working correctly!\")\n","        return True\n","\n","    except Exception as e:\n","        print(f\"❌ Error in inference testing: {str(e)}\")\n","        return False\n","\n","def check_app_readiness():\n","    \"\"\"Check if Streamlit app is ready to run\"\"\"\n","    print_step(6, \"App Readiness\", \"Verifying Streamlit app can be launched\")\n","\n","    try:\n","        # Check if app file exists\n","        if not os.path.exists('app.py'):\n","            print(\"❌ app.py not found\")\n","            return False\n","\n","        # Check if model files exist\n","        required_files = [\n","            'model/mental_health_classifier.pkl',\n","            'model/tfidf_vectorizer.pkl',\n","            'model/label_encoder.pkl',\n","            'model/model_info.pkl'\n","        ]\n","\n","        for file_path in required_files:\n","            if not os.path.exists(file_path):\n","                print(f\"❌ Required file missing: {file_path}\")\n","                return False\n","            print(f\"✓ {file_path}\")\n","\n","        print(\"\\n✅ Streamlit app is ready to launch!\")\n","        print(\"🚀 Run the app with: streamlit run app.py\")\n","        return True\n","\n","    except Exception as e:\n","        print(f\"❌ Error checking app readiness: {str(e)}\")\n","        return False\n","\n","def print_summary(start_time, success=True):\n","    \"\"\"Print pipeline execution summary\"\"\"\n","    end_time = time.time()\n","    duration = end_time - start_time\n","\n","    print(f\"\\n{'='*60}\")\n","    print(\"🏁 PIPELINE EXECUTION SUMMARY\")\n","    print(f\"{'='*60}\")\n","\n","    if success:\n","        print(\"✅ Pipeline completed successfully!\")\n","    else:\n","        print(\"❌ Pipeline failed - see errors above\")\n","\n","    print(f\"⏱️  Total execution time: {duration:.1f} seconds\")\n","    print(f\"🕐 Completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n","\n","    if success:\n","        print(f\"\\n🎉 Next Steps:\")\n","        print(f\"   1. Launch the web app: streamlit run app.py\")\n","        print(f\"   2. Open your browser to: http://localhost:8501\")\n","        print(f\"   3. Test the classifier with your own text!\")\n","        print(f\"   4. Explore the Jupyter notebook: notebooks/train_model.ipynb\")\n","\n","        print(f\"\\n📁 Generated Files:\")\n","        print(f\"   • data/raw_data.csv - Original dataset\")\n","        print(f\"   • data/processed_data.csv - Cleaned dataset\")\n","        print(f\"   • model/*.pkl - Trained model files\")\n","        print(f\"   • model/confusion_matrix.png - Model evaluation\")\n","\n","def main():\n","    \"\"\"Main pipeline execution function\"\"\"\n","    parser = argparse.ArgumentParser(description=\"Mental Health Chat Classifier Pipeline\")\n","    parser.add_argument('--skip-data', action='store_true',\n","                       help='Skip data generation if data already exists')\n","    parser.add_argument('--quick-train', action='store_true',\n","                       help='Use faster training settings')\n","    parser.add_argument('--test-only', action='store_true',\n","                       help='Only run inference testing (assumes model exists)')\n","\n","    args = parser.parse_args()\n","\n","    start_time = time.time()\n","    print_banner()\n","\n","    # Pipeline steps\n","    steps = [\n","        (\"Dependency Check\", lambda: check_dependencies()),\n","        (\"Setup Directories\", lambda: create_directories()),\n","    ]\n","\n","    if not args.test_only:\n","        steps.extend([\n","            (\"Generate Data\", lambda: generate_data(args.skip_data)),\n","            (\"Preprocess Data\", lambda: preprocess_data()),\n","            (\"Train Model\", lambda: train_model(args.quick_train)),\n","        ])\n","\n","    steps.extend([\n","        (\"Test Inference\", lambda: test_inference()),\n","        (\"Check App Readiness\", lambda: check_app_readiness()),\n","    ])\n","\n","    # Execute pipeline\n","    success = True\n","    for step_name, step_func in steps:\n","        try:\n","            if not step_func():\n","                success = False\n","                break\n","        except KeyboardInterrupt:\n","            print(f\"\\n\\n⚠️  Pipeline interrupted by user\")\n","            success = False\n","            break\n","        except Exception as e:\n","            print(f\"\\n❌ Unexpected error in {step_name}: {str(e)}\")\n","            success = False\n","            break\n","\n","    # Print summary\n","    print_summary(start_time, success)\n","\n","    return 0 if success else 1\n","\n","if __name__ == \"__main__\":\n","    sys.exit(main())"],"metadata":{"id":"gsKgcb6qhbAx"},"execution_count":null,"outputs":[]}]}